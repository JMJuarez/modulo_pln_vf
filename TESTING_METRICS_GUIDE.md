# ğŸ“Š GuÃ­a de MÃ©tricas e Indicadores de Tests

## ğŸ¯ IntroducciÃ³n

Esta guÃ­a explica cÃ³mo obtener, interpretar y utilizar las mÃ©tricas e indicadores de todos los tests del proyecto.

---

## ğŸ“‹ Tabla de Contenidos

1. [MÃ©tricas Disponibles](#mÃ©tricas-disponibles)
2. [CÃ³mo Obtener las MÃ©tricas](#cÃ³mo-obtener-las-mÃ©tricas)
3. [InterpretaciÃ³n de Resultados](#interpretaciÃ³n-de-resultados)
4. [Indicadores Clave (KPIs)](#indicadores-clave-kpis)
5. [Dashboards y Reportes](#dashboards-y-reportes)
6. [CI/CD Integration](#cicd-integration)

---

## ğŸ“Š MÃ©tricas Disponibles

### 1. **MÃ©tricas de Cobertura de CÃ³digo**

| MÃ©trica | DescripciÃ³n | Fuente |
|---------|-------------|--------|
| **Coverage %** | Porcentaje de lÃ­neas cubiertas | `coverage report` |
| **Lines Covered** | NÃºmero de lÃ­neas cubiertas | `.coverage` |
| **Branches Covered** | Cobertura de ramas (if/else) | `coverage report --branch` |
| **Missing Lines** | LÃ­neas no cubiertas | `coverage report -m` |

**Archivos generados**:
- `htmlcov/index.html` - Reporte HTML visual
- `.coverage` - Base de datos de cobertura
- `test_reports/coverage.json` - Datos en JSON
- `test_reports/coverage_report.txt` - Reporte en texto

---

### 2. **MÃ©tricas de Tests**

| MÃ©trica | DescripciÃ³n | CÃ³mo Obtenerla |
|---------|-------------|----------------|
| **Total Tests** | NÃºmero total de tests | `pytest --collect-only` |
| **Passed Tests** | Tests exitosos | `pytest -v` |
| **Failed Tests** | Tests fallidos | `pytest -v` |
| **Skipped Tests** | Tests omitidos | `pytest -v` |
| **Duration** | Tiempo de ejecuciÃ³n | `pytest --durations=0` |
| **Tests por Tipo** | Conteo por marker | `pytest -m <marker> --collect-only` |

---

### 3. **MÃ©tricas de Calidad**

| MÃ©trica | FÃ³rmula | Objetivo |
|---------|---------|----------|
| **Test Density** | Tests / 1000 lÃ­neas cÃ³digo | >10 |
| **Test Ratio** | LÃ­neas tests / LÃ­neas cÃ³digo | >0.5 |
| **Mutation Score** | Mutaciones detectadas / Total | >80% |
| **Code Complexity** | Complejidad ciclomÃ¡tica | <10 |

---

### 4. **MÃ©tricas de Rendimiento** (Performance)

| MÃ©trica | DescripciÃ³n | Objetivo |
|---------|-------------|----------|
| **Avg Latency** | Latencia promedio | <100ms |
| **P95 Latency** | Percentil 95 | <200ms |
| **P99 Latency** | Percentil 99 | <500ms |
| **Throughput** | Queries por segundo | >50 q/s |
| **Max Concurrent Users** | Usuarios simultÃ¡neos | >100 |

---

### 5. **MÃ©tricas SemÃ¡nticas** (PLN Specific)

| MÃ©trica | DescripciÃ³n | Objetivo |
|---------|-------------|----------|
| **Accuracy** | % clasificaciones correctas | >95% |
| **Precision** | True Positives / (TP + FP) | >90% |
| **Recall** | True Positives / (TP + FN) | >90% |
| **F1-Score** | Media armÃ³nica P y R | >90% |
| **Confusion Matrix** | Matriz de confusiÃ³n | AnÃ¡lisis |

---

## ğŸš€ CÃ³mo Obtener las MÃ©tricas

### OpciÃ³n 1: Script Automatizado (MÃS FÃCIL)

```bash
# Ejecutar script interactivo
./run_test_metrics.sh

# Opciones disponibles:
# 1) Resumen RÃ¡pido       - Solo conteo y estadÃ­sticas
# 2) Todos los Tests      - Ejecutar todos y generar reportes
# 3) Por Tipo             - Reportes separados por tipo
# 4) Solo Cobertura       - AnÃ¡lisis de cobertura
# 5) MÃ©tricas Avanzadas   - MÃ©tricas de calidad
# 6) Reportes HTML        - Ãndice HTML visual
# 7) Todo (Suite Completa) - Todos los reportes
```

**Output**:
- `test_reports/` - Todos los reportes
- `test_reports/index.html` - Dashboard HTML
- `htmlcov/index.html` - Cobertura visual

---

### OpciÃ³n 2: Comandos Manuales

#### A. **Cobertura de CÃ³digo**

```bash
# Ejecutar tests con cobertura
pytest --cov=app --cov-report=html --cov-report=term

# Ver reporte en terminal
coverage report

# Ver reporte detallado (con lÃ­neas faltantes)
coverage report -m

# Generar reporte JSON
coverage json -o test_reports/coverage.json

# Abrir reporte HTML
xdg-open htmlcov/index.html  # Linux
open htmlcov/index.html       # macOS
```

---

#### B. **Conteo de Tests**

```bash
# Contar todos los tests
pytest --collect-only -q | grep "test_" | wc -l

# Por tipo (markers)
pytest --collect-only -q -m unit | grep "test_" | wc -l
pytest --collect-only -q -m integration | grep "test_" | wc -l
pytest --collect-only -q -m e2e | grep "test_" | wc -l
pytest --collect-only -q -m semantic | grep "test_" | wc -l
pytest --collect-only -q -m performance | grep "test_" | wc -l
```

---

#### C. **Ejecutar Tests con Reportes**

```bash
# Reporte HTML con pytest-html
pytest --html=test_reports/report.html --self-contained-html

# Reporte JUnit XML (para CI/CD)
pytest --junit-xml=test_reports/junit.xml

# Con cobertura y reportes
pytest \
    --cov=app \
    --cov-report=html \
    --cov-report=term-missing \
    --html=test_reports/report.html \
    --junit-xml=test_reports/junit.xml \
    -v
```

---

#### D. **MÃ©tricas de Performance**

```bash
# DuraciÃ³n de tests mÃ¡s lentos
pytest --durations=10

# Todos los durations
pytest --durations=0

# Solo tests de performance
pytest tests/performance/ -v --durations=0

# Benchmarks con pytest-benchmark
pytest tests/performance/test_benchmarks.py --benchmark-only
```

---

#### E. **MÃ©tricas SemÃ¡nticas**

```bash
# Tests semÃ¡nticos con mÃ©tricas
pytest tests/quality/ -v -s

# Ver confusion matrix
pytest tests/quality/test_semantic_advanced.py::TestConfusionMatrixDetailed -v -s

# Ver distribuciÃ³n de similitudes
pytest tests/quality/test_semantic_advanced.py::TestSimilarityDistribution -v -s
```

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### 1. **Reporte de Cobertura**

```
Name                     Stmts   Miss  Cover   Missing
------------------------------------------------------
app/__init__.py              0      0   100%
app/main.py                145     12    92%   45-47, 67-69
app/matcher_improved.py    256     23    91%   234-245
app/preprocess.py           89      5    94%   78-82
------------------------------------------------------
TOTAL                      490     40    92%
```

**InterpretaciÃ³n**:
- âœ… **>90%**: Excelente cobertura
- âš ï¸ **70-90%**: Buena, pero mejorable
- âŒ **<70%**: Necesita mÃ¡s tests

**QuÃ© buscar**:
- LÃ­neas crÃ­ticas sin cubrir (`Missing`)
- Funciones de error handling sin tests
- CÃ³digo nuevo sin tests

---

### 2. **Reporte de Tests**

```
tests/unit/test_matcher.py::TestClipSimilarity::test_clip_normal_value PASSED [ 10%]
tests/unit/test_matcher.py::TestClipSimilarity::test_clip_above_one PASSED [ 20%]
tests/integration/test_api.py::TestBuscarEndpoint::test_buscar_valid_query PASSED [ 30%]
...
======================== 150 passed, 2 failed, 3 skipped in 45.23s ========================
```

**MÃ©tricas clave**:
- **Passed**: Tests exitosos
- **Failed**: Tests fallidos (INVESTIGAR)
- **Skipped**: Tests omitidos (normal si estÃ¡n marcados)
- **Duration**: Tiempo total

**AnÃ¡lisis**:
- âœ… **0 failed**: Perfecto
- âš ï¸ **1-3 failed**: Investigar y corregir
- âŒ **>3 failed**: Problema serio

---

### 3. **MÃ©tricas de Performance**

```
ğŸ“Š CONCURRENT LOAD TEST (10 usuarios):
   Total queries:     100
   Exitosas:          98/100 (98.0%)
   Latencia promedio: 45.23ms      âœ… Bueno
   Latencia P95:      89.12ms      âœ… Bueno
   Throughput:        52.3 q/s     âœ… Bueno
```

**Indicadores**:
- âœ… Latencia promedio <100ms
- âœ… P95 <200ms
- âœ… Throughput >50 q/s
- âœ… Success rate >95%

---

### 4. **Matriz de ConfusiÃ³n (SemÃ¡ntica)**

```
ğŸ“Š MATRIZ DE CONFUSIÃ“N:
Predicted â†’     A         B         C         None
------------------------------------------------------
A              8         1         0         1        â† 80% accuracy
B              0        10         0         0        â† 100% accuracy
C              1         0         9         0        â† 90% accuracy
Deletreo       1         0         0         0        â† Falso negativo

Grupo A:
  Accuracy:  80.0%
  Precision: 88.9%
  Recall:    80.0%
  F1-Score:  84.2%
```

**InterpretaciÃ³n**:
- **Diagonal**: Clasificaciones correctas
- **Fuera de diagonal**: Errores (analizar)
- **Precision**: De lo que predije como A, cuÃ¡ntos eran realmente A
- **Recall**: De todos los A reales, cuÃ¡ntos detectÃ©

---

## ğŸ¯ Indicadores Clave (KPIs)

### KPIs de Cobertura

| KPI | FÃ³rmula | Objetivo | Estado Actual |
|-----|---------|----------|---------------|
| **Code Coverage** | LÃ­neas cubiertas / Total lÃ­neas Ã— 100 | >90% | Ver reporte |
| **Branch Coverage** | Ramas cubiertas / Total ramas Ã— 100 | >80% | Ver reporte |
| **Function Coverage** | Funciones con tests / Total funciones Ã— 100 | >95% | Ver reporte |

---

### KPIs de Calidad

| KPI | Objetivo | CÃ³mo Medir |
|-----|----------|------------|
| **Test Pass Rate** | >99% | `pytest -v` |
| **Test Execution Time** | <5 min | `pytest --durations=0` |
| **Flaky Tests** | 0 | Ejecutar 3 veces |
| **Test Maintenance Ratio** | <20% | Tiempo de fix / Tiempo total |

---

### KPIs de Rendimiento

| KPI | Objetivo | CÃ³mo Medir |
|-----|----------|------------|
| **Average Latency** | <100ms | `pytest tests/performance/` |
| **P95 Latency** | <200ms | Ver reportes de performance |
| **Throughput** | >50 q/s | Ver reportes de Locust |
| **Max Concurrent Users** | >100 | Tests de estrÃ©s |
| **Error Rate** | <1% | Success rate en load tests |

---

### KPIs SemÃ¡nticos (PLN)

| KPI | Objetivo | CÃ³mo Medir |
|-----|----------|------------|
| **Classification Accuracy** | >95% | Tests semÃ¡nticos |
| **Precision (promedio)** | >90% | Confusion matrix |
| **Recall (promedio)** | >90% | Confusion matrix |
| **F1-Score (promedio)** | >90% | Tests de calidad |
| **Robustez ante Typos** | >70% | Tests de robustez |

---

## ğŸ“± Dashboards y Reportes

### 1. **Dashboard HTML Principal**

```bash
# Generar dashboard
./run_test_metrics.sh
# Seleccionar opciÃ³n 6 o 7

# Abrir dashboard
xdg-open test_reports/index.html
```

**Contiene**:
- ğŸ“Š MÃ©tricas generales
- ğŸ“‘ Enlaces a reportes HTML
- ğŸ“ˆ EstadÃ­sticas por tipo
- ğŸ“„ Archivos descargables (XML, JSON)

---

### 2. **Reporte de Cobertura Visual**

```bash
xdg-open htmlcov/index.html
```

**CaracterÃ­sticas**:
- Vista por archivo
- LÃ­neas cubiertas en verde
- LÃ­neas no cubiertas en rojo
- NavegaciÃ³n interactiva

---

### 3. **Reportes por Tipo**

Generados en `test_reports/`:
- `report_all.html` - Todos los tests
- `report_unit.html` - Solo unitarios
- `report_integration.html` - Solo integraciÃ³n
- `report_e2e.html` - Solo E2E
- `report_semantic.html` - Solo semÃ¡nticos
- `report_performance.html` - Solo performance

---

## ğŸ”„ CI/CD Integration

### GitHub Actions Example

```yaml
name: Tests & Metrics

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Run tests with coverage
        run: |
          pytest \
            --cov=app \
            --cov-report=xml \
            --cov-report=html \
            --junit-xml=junit.xml \
            --html=report.html \
            --self-contained-html

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v2
        with:
          files: ./coverage.xml

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: junit.xml

      - name: Upload HTML reports
        uses: actions/upload-artifact@v2
        with:
          name: test-reports
          path: |
            htmlcov/
            report.html
```

---

### Badges para README

```markdown
![Tests](https://github.com/user/repo/workflows/Tests/badge.svg)
![Coverage](https://codecov.io/gh/user/repo/branch/main/graph/badge.svg)
```

---

## ğŸ“Š Ejemplo de Resumen Completo

DespuÃ©s de ejecutar `./run_test_metrics.sh` (opciÃ³n 7), obtendrÃ¡s:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  RESUMEN DE MÃ‰TRICAS DE TESTS                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Fecha de generaciÃ³n: 2025-11-26 20:45:32

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š CONTEO DE TESTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Total de tests:                 150
â”œâ”€ Unitarios:                   45 (30.0%)
â”œâ”€ IntegraciÃ³n:                 25 (16.7%)
â”œâ”€ End-to-End:                  40 (26.7%)
â”œâ”€ SemÃ¡nticos:                  30 (20.0%)
â”œâ”€ Performance:                 10 (6.7%)
â””â”€ Lentos (>5s):                8 (5.3%)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š COBERTURA DE CÃ“DIGO
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Cobertura total: 92%

Reportes disponibles:
  - HTML:  htmlcov/index.html
  - JSON:  test_reports/coverage.json
  - Texto: test_reports/coverage_report.txt

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ MÃ‰TRICAS DE CALIDAD
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Ratio de tests:
  - Tests por 1000 lÃ­neas de cÃ³digo: 12.5
  - LÃ­neas de tests / LÃ­neas de cÃ³digo: 1.8

PirÃ¡mide de tests (ideal: 70% unit, 20% integration, 10% e2e):
  - Unitarios:    30.0%  âš ï¸  (objetivo: 70%)
  - IntegraciÃ³n:  16.7%
  - E2E:          26.7%  âš ï¸  (objetivo: 10%)

Tests especializados:
  - SemÃ¡nticos (PLN):  30 tests
  - Performance:       10 tests
  - Robustez:          5 clases
```

---

## ğŸ“ Mejores PrÃ¡cticas

### 1. **Frecuencia de EjecuciÃ³n**

| Tests | Frecuencia |
|-------|------------|
| Unit | Cada commit (pre-commit hook) |
| Integration | Cada push |
| E2E | Cada merge a main |
| Performance | Semanal |
| Stress | Mensual |

---

### 2. **Umbrales Recomendados**

```yaml
coverage:
  min: 90%
  target: 95%

performance:
  avg_latency: 100ms
  p95_latency: 200ms
  throughput: 50qps

quality:
  test_pass_rate: 99%
  accuracy: 95%
  precision: 90%
  recall: 90%
```

---

### 3. **Alertas y Notificaciones**

Configurar alertas cuando:
- âŒ Cobertura cae <90%
- âŒ Tests fallan >1%
- âŒ Latencia promedio >100ms
- âŒ Accuracy <95%

---

## ğŸ“ Soporte

Para preguntas sobre mÃ©tricas:
1. Revisar esta guÃ­a
2. Ejecutar `./run_test_metrics.sh` opciÃ³n 1 (resumen rÃ¡pido)
3. Abrir dashboard HTML: `xdg-open test_reports/index.html`
4. Crear issue en el repositorio

---

**Ãšltima actualizaciÃ³n**: 2025-11-26
