# ğŸš€ Performance & Stress Testing

Suite completa de tests de rendimiento, carga y estrÃ©s para el mÃ³dulo de PLN.

## ğŸ“ Estructura

```
tests/performance/
â”œâ”€â”€ README.md                      # Este archivo
â”œâ”€â”€ STRESS_TESTING_GUIDE.md        # GuÃ­a detallada de tests de estrÃ©s
â”œâ”€â”€ test_benchmarks.py             # Benchmarks bÃ¡sicos (latencia, throughput)
â”œâ”€â”€ test_stress_concurrent.py      # Tests de concurrencia y estrÃ©s (NUEVO)
â”œâ”€â”€ locustfile.py                  # ConfiguraciÃ³n de Locust para load testing (NUEVO)
â””â”€â”€ stress_results/                # Directorio para resultados (autogenerado)
```

## âš¡ Quick Start

### OpciÃ³n 1: Script Automatizado (MÃ¡s FÃ¡cil)

```bash
# Ejecutar script interactivo
./run_stress_tests.sh

# Seleccionar opciÃ³n del menÃº
# Recomendado para empezar: OpciÃ³n 1 (Quick Test)
```

### OpciÃ³n 2: Tests Individuales

```bash
# Tests de benchmarks bÃ¡sicos (rÃ¡pido)
pytest tests/performance/test_benchmarks.py -v -s

# Tests de concurrencia
pytest tests/performance/test_stress_concurrent.py::TestConcurrentLoad -v -s

# Locust con UI web
locust -f tests/performance/locustfile.py --host=http://localhost:8000
# Luego abre: http://localhost:8089
```

## ğŸ“Š Tipos de Tests

| Tipo | Archivo | DuraciÃ³n | PropÃ³sito |
|------|---------|----------|-----------|
| **Benchmarks** | `test_benchmarks.py` | <1 min | Latencia, throughput baseline |
| **Concurrencia** | `test_stress_concurrent.py` | 2-5 min | MÃºltiples usuarios simultÃ¡neos |
| **Spike** | `test_stress_concurrent.py` | <1 min | Picos sÃºbitos de carga |
| **Soak** | `test_stress_concurrent.py` | 5-10 min | Carga sostenida (memory leaks) |
| **Locust** | `locustfile.py` | Variable | SimulaciÃ³n realista de usuarios |

## ğŸ¯ MÃ©tricas Objetivo

| MÃ©trica | Objetivo | CrÃ­tico |
|---------|----------|---------|
| Latencia P50 | <100ms | >200ms |
| Latencia P95 | <200ms | >500ms |
| Success Rate | >95% | <90% |
| Throughput | >50 q/s | <30 q/s |
| Max Users | 100+ | <50 |

## ğŸ”¥ Tests de EstrÃ©s Disponibles

### 1. Concurrent Load Testing

```bash
# 10 usuarios concurrentes
pytest tests/performance/test_stress_concurrent.py::TestConcurrentLoad::test_concurrent_10_users -v -s

# 50 usuarios concurrentes
pytest tests/performance/test_stress_concurrent.py::TestConcurrentLoad::test_concurrent_50_users -v -s

# 100 usuarios (breaking point)
pytest tests/performance/test_stress_concurrent.py::TestConcurrentLoad::test_concurrent_100_users_breaking_point -v -s
```

### 2. Spike Testing

```bash
# Spike sÃºbito: 0 â†’ 20 usuarios
pytest tests/performance/test_stress_concurrent.py::TestSpikeLoad::test_sudden_spike_0_to_20_users -v -s
```

### 3. Soak Testing (Endurance)

```bash
# Carga sostenida 5 minutos
pytest tests/performance/test_stress_concurrent.py::TestSoakTesting::test_sustained_load_5_minutes -v -s -m slow
```

### 4. Locust Load Testing

```bash
# Light load (10 usuarios, 2 min)
locust -f tests/performance/locustfile.py --host=http://localhost:8000 \
       --users 10 --spawn-rate 2 --run-time 2m --headless

# Moderate load (50 usuarios, 5 min)
locust -f tests/performance/locustfile.py --host=http://localhost:8000 \
       --users 50 --spawn-rate 5 --run-time 5m --headless

# Heavy load (100 usuarios, 5 min)
locust -f tests/performance/locustfile.py --host=http://localhost:8000 \
       --users 100 --spawn-rate 10 --run-time 5m --headless

# Con reportes HTML
locust -f tests/performance/locustfile.py --host=http://localhost:8000 \
       --users 50 --spawn-rate 5 --run-time 5m --headless \
       --csv=results --html=report.html
```

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Output de pytest

```
ğŸ“Š CONCURRENT LOAD TEST (10 usuarios):
   Total queries:     100
   Exitosas:          98/100 (98.0%)
   Respuestas vÃ¡lidas: 98/100 (98.0%)
   Latencia promedio: 45.23ms      # âœ… Bueno (<100ms)
   Latencia P95:      89.12ms      # âœ… Bueno (<200ms)
   Throughput:        52.3 q/s     # âœ… Bueno (>50 q/s)
```

### Reportes de Locust

Los reportes HTML se generan en `stress_results/` con:
- Request statistics
- Response time charts
- Failure rate
- Users over time

**QuÃ© buscar**:
- âœ… Failure rate <1%
- âœ… Response time estable
- âœ… RPS constante
- âŒ Picos de latencia >1s
- âŒ Failure rate >5%

## ğŸ”§ Prerequisitos

### 1. Servidor corriendo

```bash
# Verificar
curl http://localhost:8000/health

# Si no estÃ¡ corriendo:
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### 2. Dependencias instaladas

```bash
pip install -r requirements-test.txt
```

### 3. Recursos suficientes

- RAM: 4GB+ disponible
- CPU: 2+ cores
- File descriptors: ulimit -n >= 1024

## ğŸ› Troubleshooting

### "Connection refused"
```bash
# Asegurar que el servidor estÃ¡ corriendo
uvicorn app.main:app --reload
```

### "Too many open files"
```bash
# Aumentar lÃ­mite
ulimit -n 4096
```

### Latencias muy altas
```bash
# Warm-up del modelo primero
pytest tests/performance/test_benchmarks.py::TestInitializationPerformance::test_initialization_with_cache -v
```

### Locust no encuentra archivo
```bash
# Ejecutar desde directorio raÃ­z del proyecto
cd /path/to/modulo_pln
locust -f tests/performance/locustfile.py --host=http://localhost:8000
```

## ğŸ“š DocumentaciÃ³n Detallada

Ver **[STRESS_TESTING_GUIDE.md](STRESS_TESTING_GUIDE.md)** para:
- ExplicaciÃ³n detallada de cada tipo de test
- MetodologÃ­as utilizadas
- AnÃ¡lisis avanzado de resultados
- Best practices
- Troubleshooting extendido

## ğŸ“ Ejemplos de Uso

### Escenario 1: ValidaciÃ³n rÃ¡pida antes de deploy

```bash
# Quick test (30 segundos)
./run_stress_tests.sh
# Seleccionar: 1 (Quick Test)
```

### Escenario 2: ValidaciÃ³n completa semanal

```bash
# Full suite (30+ minutos)
./run_stress_tests.sh
# Seleccionar: 8 (Full Suite)
```

### Escenario 3: Encontrar lÃ­mite del sistema

```bash
# Breaking point test
pytest tests/performance/test_stress_concurrent.py::TestConcurrentLoad::test_concurrent_100_users_breaking_point -v -s
```

### Escenario 4: Simular trÃ¡fico real durante 5 minutos

```bash
# Locust con mix realista de usuarios
locust -f tests/performance/locustfile.py --host=http://localhost:8000 \
       --users 50 --spawn-rate 5 --run-time 5m --headless \
       --html=report.html
```

## ğŸ“Š CI/CD Integration

### GitHub Actions Example

```yaml
name: Stress Tests

on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly
  workflow_dispatch:      # Manual trigger

jobs:
  stress-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements-test.txt
      - name: Start server
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
      - name: Run stress tests
        run: |
          pytest tests/performance/test_stress_concurrent.py -v -s -m "performance and not slow"
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: stress-test-results
          path: stress_results/
```

## ğŸš€ Roadmap

### âœ… Implementado
- [x] Tests de concurrencia bÃ¡sicos
- [x] Tests de spike
- [x] Soak testing
- [x] Locust integration
- [x] Script automatizado
- [x] Reportes HTML/CSV

### ğŸš§ PrÃ³ximos pasos
- [ ] Distributed Locust (mÃºltiples workers)
- [ ] Grafana dashboards
- [ ] CI/CD integration
- [ ] Chaos engineering tests

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisar [STRESS_TESTING_GUIDE.md](STRESS_TESTING_GUIDE.md)
2. Revisar comentarios en el cÃ³digo
3. Crear issue en el repositorio

---

**Ãšltima actualizaciÃ³n**: 2025-11-26
